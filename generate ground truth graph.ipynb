{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"amazon-meta_filtered_ground_truth.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "    #print training_set\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n",
      "1233\n"
     ]
    }
   ],
   "source": [
    "#read in graph\n",
    "G = nx.Graph()\n",
    "all_nodes_inorder = [];\n",
    "for t in training_set:\n",
    "    all_nodes_inorder.append(t[0]);\n",
    "\n",
    "    for i in range(len(t)):\n",
    "        source = t[i]\n",
    "        for j in range(i+1,len(t)):\n",
    "            target = t[j]\n",
    "            G.add_node(source)\n",
    "            G.add_node(target)\n",
    "            G.add_edge(source,target)\n",
    "print len(G.nodes())\n",
    "print(len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545\n",
      "725\n"
     ]
    }
   ],
   "source": [
    "print len(all_nodes_inorder)\n",
    "print len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "101 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "#random adding node\n",
    "item_item = []\n",
    "\n",
    "for t in training_set:\n",
    "    for i in range(len(t)):\n",
    "        source = t[i]\n",
    "        for j in range(i+1,len(t)):\n",
    "            target = t[j]\n",
    "            item_item.append([source,target,1])\n",
    "\n",
    "count_one = 0\n",
    "counter = 0\n",
    "node_set = G.nodes()\n",
    "to_keep = random.sample(range(len(node_set)), k=int(round(len(node_set))*0.1))\n",
    "node_set_reduced = [node_set[i] for i in to_keep]\n",
    "for i in xrange(len(node_set_reduced)):\n",
    "    source = node_set_reduced[i]\n",
    "    for j in xrange(len(node_set_reduced)):\n",
    "        target = node_set_reduced[j]\n",
    "        if (source in node_set_reduced) and (target in node_set_reduced) and (source != target):\n",
    "            if nx.has_path(G,source,target):\n",
    "                dist = nx.shortest_path_length(G,source,target)\n",
    "                if dist == 1:\n",
    "                    #item_item.append([source,target,1])\n",
    "                    count_one += 1\n",
    "                else:\n",
    "                    item_item.append([source,target,0])\n",
    "            else:\n",
    "                item_item.append([source,target,-1])\n",
    "            \n",
    "    counter += 1\n",
    "    if counter % 100 == True:\n",
    "        print counter, \"training examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "101 training examples processsed\n",
      "201 training examples processsed\n",
      "301 training examples processsed\n",
      "401 training examples processsed\n",
      "501 training examples processsed\n",
      "601 training examples processsed\n",
      "701 training examples processsed\n",
      "801 training examples processsed\n",
      "901 training examples processsed\n",
      "1001 training examples processsed\n",
      "1101 training examples processsed\n",
      "1201 training examples processsed\n",
      "1301 training examples processsed\n",
      "1401 training examples processsed\n",
      "1501 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "# adding all nodes\n",
    "item_item = []\n",
    "\n",
    "counter = 0\n",
    "node_set = G.nodes()\n",
    "#to_keep = random.sample(range(len(node_set)), k=int(round(len(node_set))*0.1))\n",
    "#node_set_reduced = [node_set[i] for i in to_keep]\n",
    "for i in xrange(len(all_nodes_inorder)):\n",
    "    source = all_nodes_inorder[i]\n",
    "    for j in xrange(len(all_nodes_inorder)):\n",
    "        target = all_nodes_inorder[j]\n",
    "        if (source in node_set) and (target in node_set) and (source != target):\n",
    "            if nx.has_path(G,source,target):\n",
    "                dist = nx.shortest_path_length(G,source,target)\n",
    "                if dist == 1:\n",
    "                    item_item.append([source,target,1])\n",
    "                else:\n",
    "                    item_item.append([source,target,0])\n",
    "            else:\n",
    "                item_item.append([source,target,-1])\n",
    "    counter += 1\n",
    "    if counter % 100 == True:\n",
    "        print counter, \"training examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thefile = open('amazon-meta_item_item_0.txt', 'w')\n",
    "for item in item_item:\n",
    "    thefile.write(\"%s %s %s\\n\" % (item[0],item[1],item[2]))\n",
    "thefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289162\n",
      "233272\n",
      "2466\n"
     ]
    }
   ],
   "source": [
    "count_n1 = 0\n",
    "count_zero = 0\n",
    "count_p1 = 0\n",
    "for item in item_item:\n",
    "    if item[2] == -1:\n",
    "        count_n1 += 1\n",
    "    elif item[2] == 0:\n",
    "        count_zero += 1\n",
    "    elif item[2] == 1:\n",
    "        count_p1 += 1\n",
    "print(count_n1)\n",
    "print(count_zero)\n",
    "print(count_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
