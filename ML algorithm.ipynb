{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/collinli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/collinli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "#import igraph\n",
    "import csv\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import networkx as nx\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import math\n",
    "\n",
    "nltk.download('punkt') # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calcualte inner product\n",
    "def inner(X,Y):\n",
    "    s = 0\n",
    "    for i in range(0,len(X)):\n",
    "        s = s + X[i]*Y[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in training set and node information\n",
    "with open(\"amazon-meta_item_item_0.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training_set  = list(reader)\n",
    "\n",
    "training_set = [element[0].split(\" \") for element in training_set]\n",
    "\n",
    "with open(\"amazon-meta_item_info.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f,delimiter='^')\n",
    "    node_info  = list(reader)\n",
    "\n",
    "node_info = node_info[1:]\n",
    "IDs = [element[0] for element in node_info]\n",
    "\n",
    "# compute TFIDF vector for titles of products\n",
    "title = [element[1] for element in node_info]\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "# each row is a node in the order of node_info\n",
    "features_TFIDF = vectorizer.fit_transform(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in testing set\n",
    "with open(\"amazon-meta_filtered_ground_truth.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing_list  = list(reader)\n",
    "    \n",
    "#testing_list = [element[0].split(\" \")[0] for element in testing_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262450\n",
      "262450\n"
     ]
    }
   ],
   "source": [
    "# randomize training set and split in half \n",
    "# half for training and half for testing\n",
    "to_keep = random.sample(range(len(training_set)), k=int(round(len(training_set))))\n",
    "training_set_reduced_total = [training_set[i] for i in to_keep]\n",
    "#create a local test set\n",
    "training_set_reduced = training_set_reduced_total[:len(training_set_reduced_total)/2]\n",
    "testing_set = training_set_reduced_total[len(training_set_reduced_total)/2:]\n",
    "print(len(training_set_reduced))\n",
    "print(len(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in graph, each node represents an item\n",
    "training_set_reduced_total = [training_set[i] for i in to_keep]\n",
    "G = nx.Graph()\n",
    "for t in training_set_reduced_total:\n",
    "    G.add_node(t[0])\n",
    "    G.add_node(t[1])\n",
    "    if t[2] == '1':\n",
    "        G.add_edge(t[0],t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "10001 training examples processsed\n",
      "20001 training examples processsed\n",
      "30001 training examples processsed\n",
      "40001 training examples processsed\n",
      "50001 training examples processsed\n",
      "60001 training examples processsed\n",
      "70001 training examples processsed\n",
      "80001 training examples processsed\n",
      "90001 training examples processsed\n",
      "100001 training examples processsed\n",
      "110001 training examples processsed\n",
      "120001 training examples processsed\n",
      "130001 training examples processsed\n",
      "140001 training examples processsed\n",
      "150001 training examples processsed\n",
      "160001 training examples processsed\n",
      "170001 training examples processsed\n",
      "180001 training examples processsed\n",
      "190001 training examples processsed\n",
      "200001 training examples processsed\n",
      "210001 training examples processsed\n",
      "220001 training examples processsed\n",
      "230001 training examples processsed\n",
      "240001 training examples processsed\n",
      "250001 training examples processsed\n",
      "260001 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "# title TFIDF cos similarity\n",
    "title_similarity = []\n",
    "\n",
    "# group is the same or not\n",
    "group_similarity = []\n",
    "\n",
    "# number of reviews\n",
    "reviews_num_similarity = []\n",
    "\n",
    "# same number of words in detailed category\n",
    "category_similarity = []\n",
    "\n",
    "# rating \n",
    "rating_similarity = []\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(training_set_reduced)):\n",
    "#for i in range(1):\n",
    "    source = training_set_reduced[i][0]\n",
    "    target = training_set_reduced[i][1]\n",
    "    \n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    source_info = [element for element in node_info if element[0]==source][0]\n",
    "    target_info = [element for element in node_info if element[0]==target][0]\n",
    "    \n",
    "\t# calculate title TFIDF cos similarity\n",
    "    source_title_tfidf = features_TFIDF[index_source].toarray()[0]\n",
    "    target_title_tfidf = features_TFIDF[index_target].toarray()[0]\n",
    "    \n",
    "    cos = np.dot(source_title_tfidf,target_title_tfidf) / (np.linalg.norm(np.array(source_title_tfidf))\\\n",
    "       *np.linalg.norm(np.array(target_title_tfidf)))\n",
    "    title_similarity.append(cos)\n",
    "    \n",
    "    #group similarity true or false\n",
    "    group_source = source_info[2]\n",
    "    group_target = target_info[2]\n",
    "    \n",
    "    if group_source == group_target:\n",
    "        group_similarity.append(1)\n",
    "    else:\n",
    "        group_similarity.append(0)\n",
    "        \n",
    "    # number of reviews similarity\n",
    "    review_source = source_info[4]\n",
    "    review_target = target_info[4]\n",
    "    \n",
    "    reviews_num_similarity.append(np.absolute(int(review_source)-int(review_target)))\n",
    "    \n",
    "    # same number of words in detailed category\n",
    "    category_source = source_info[6+int(review_source)*4:]\n",
    "    category_target = target_info[6+int(review_target)*4:]\n",
    "    \n",
    "    category_similarity.append(len(set(category_source).intersection(set(category_target))))\n",
    "    \n",
    "    # rating similarity\n",
    "    rating_source = source_info[5]\n",
    "    rating_target = target_info[5]\n",
    "    \n",
    "    rating_similarity.append(np.absolute(float(rating_source)-float(rating_target)))\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 10000 == True:\n",
    "        print counter, \"training examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eliminate NaN because of bad tokenizations in titles\n",
    "# some products have trivial title after tokenization\n",
    "for i in range(len(title_similarity)):\n",
    "    if math.isnan(title_similarity[i]):\n",
    "        title_similarity[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum of nodes' degrees \n",
    "node_degree = []\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(training_set_reduced)):\n",
    "    source = training_set_reduced[i][0]\n",
    "    target = training_set_reduced[i][1]\n",
    "    \n",
    "    #add node degree\n",
    "    source_degree = G.degree(source)\n",
    "    target_degree = G.degree(target)\n",
    "    if isinstance(source_degree,dict):\n",
    "        source_degree = 0\n",
    "    if isinstance(target_degree,dict):\n",
    "        target_degree = 0\n",
    "    node_degree.append(source_degree+target_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distance between two nodes in graph\n",
    "dist_node = []\n",
    "\n",
    "counter = 0\n",
    "node_set = G.nodes()\n",
    "for i in xrange(len(training_set_reduced)):\n",
    "    source = training_set_reduced[i][0]\n",
    "    target = training_set_reduced[i][1]\n",
    "    if (source in node_set) and (target in node_set) and nx.has_path(G,source,target):\n",
    "        dist_node.append(-nx.shortest_path_length(G,source,target))\n",
    "    else:\n",
    "        dist_node.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "10001 training examples processsed\n",
      "20001 training examples processsed\n",
      "30001 training examples processsed\n",
      "40001 training examples processsed\n",
      "50001 training examples processsed\n",
      "60001 training examples processsed\n",
      "70001 training examples processsed\n",
      "80001 training examples processsed\n",
      "90001 training examples processsed\n",
      "100001 training examples processsed\n",
      "110001 training examples processsed\n",
      "120001 training examples processsed\n",
      "130001 training examples processsed\n",
      "140001 training examples processsed\n",
      "150001 training examples processsed\n",
      "160001 training examples processsed\n",
      "170001 training examples processsed\n",
      "180001 training examples processsed\n",
      "190001 training examples processsed\n",
      "200001 training examples processsed\n",
      "210001 training examples processsed\n",
      "220001 training examples processsed\n",
      "230001 training examples processsed\n",
      "240001 training examples processsed\n",
      "250001 training examples processsed\n",
      "260001 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "# number of common neighbors\n",
    "common_neighbors = []\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(training_set_reduced)):\n",
    "#for i in range(1):\n",
    "    source = training_set_reduced[i][0]\n",
    "    target = training_set_reduced[i][1]\n",
    "    \n",
    "    #add node degree\n",
    "    common_neighbors.append(len(list(nx.common_neighbors(G,source,target))))\n",
    "    counter += 1\n",
    "    if counter % 10000 == True:\n",
    "        print counter, \"training examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert list of lists into array\n",
    "# documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "training_features = np.array([title_similarity, group_similarity, category_similarity,reviews_num_similarity,rating_similarity,node_degree,dist_node,common_neighbors]).T\n",
    "\n",
    "# scale\n",
    "training_features = preprocessing.scale(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert labels into integers then into column array\n",
    "labels = [int(element[2]) for element in training_set_reduced]\n",
    "labels = list(labels)\n",
    "labels_array = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LinearSVC balanced\n",
    "classifier = svm.LinearSVC(class_weight='balanced')\n",
    "# train\n",
    "classifier.fit(training_features, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LinearSVC \n",
    "classifier = svm.LinearSVC()\n",
    "# train\n",
    "classifier.fit(training_features, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC\n",
    "classifier = svm.SVC()\n",
    "# train\n",
    "classifier.fit(training_features, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree regressor\n",
    "classifier = DecisionTreeRegressor(max_depth=2)\n",
    "classifier.fit(training_features, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.09495048e-02   2.77555756e-17   3.72653250e-03  -9.03532003e-03\n",
      "   4.50621094e-03   4.16426381e-02  -4.41159090e-01   1.06134825e-01]\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "theta = np.linalg.lstsq(training_features, labels_array)[0]\n",
    "print theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for easier measurement of testing results\n",
    "testing_set = training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 testing examples processsed\n",
      "10001 testing examples processsed\n",
      "20001 testing examples processsed\n",
      "30001 testing examples processsed\n",
      "40001 testing examples processsed\n",
      "50001 testing examples processsed\n",
      "60001 testing examples processsed\n",
      "70001 testing examples processsed\n",
      "80001 testing examples processsed\n",
      "90001 testing examples processsed\n",
      "100001 testing examples processsed\n",
      "110001 testing examples processsed\n",
      "120001 testing examples processsed\n",
      "130001 testing examples processsed\n",
      "140001 testing examples processsed\n",
      "150001 testing examples processsed\n",
      "160001 testing examples processsed\n",
      "170001 testing examples processsed\n",
      "180001 testing examples processsed\n",
      "190001 testing examples processsed\n",
      "200001 testing examples processsed\n",
      "210001 testing examples processsed\n",
      "220001 testing examples processsed\n",
      "230001 testing examples processsed\n",
      "240001 testing examples processsed\n",
      "250001 testing examples processsed\n",
      "260001 testing examples processsed\n",
      "270001 testing examples processsed\n",
      "280001 testing examples processsed\n",
      "290001 testing examples processsed\n",
      "300001 testing examples processsed\n",
      "310001 testing examples processsed\n",
      "320001 testing examples processsed\n",
      "330001 testing examples processsed\n",
      "340001 testing examples processsed\n",
      "350001 testing examples processsed\n",
      "360001 testing examples processsed\n",
      "370001 testing examples processsed\n",
      "380001 testing examples processsed\n",
      "390001 testing examples processsed\n",
      "400001 testing examples processsed\n",
      "410001 testing examples processsed\n",
      "420001 testing examples processsed\n",
      "430001 testing examples processsed\n",
      "440001 testing examples processsed\n",
      "450001 testing examples processsed\n",
      "460001 testing examples processsed\n",
      "470001 testing examples processsed\n",
      "480001 testing examples processsed\n",
      "490001 testing examples processsed\n",
      "500001 testing examples processsed\n",
      "510001 testing examples processsed\n",
      "520001 testing examples processsed\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# we need to compute the features for the testing set\n",
    "\n",
    "title_similarity_test = []\n",
    "group_similarity_test = []\n",
    "reviews_num_similarity_test = []\n",
    "category_similarity_test = []\n",
    "rating_similarity_test = []\n",
    "   \n",
    "counter = 0\n",
    "for i in xrange(len(testing_set)):\n",
    "#for i in range(50):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    \n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    \n",
    "    source_info = [element for element in node_info if element[0]==source][0]\n",
    "    target_info = [element for element in node_info if element[0]==target][0]\n",
    "    \n",
    "\t# calculate title TFIDF cos similarity\n",
    "    source_title_tfidf = features_TFIDF[index_source].toarray()[0]\n",
    "    target_title_tfidf = features_TFIDF[index_target].toarray()[0]\n",
    "    \n",
    "    cos = np.dot(source_title_tfidf,target_title_tfidf) / (np.linalg.norm(np.array(source_title_tfidf))\\\n",
    "       *np.linalg.norm(np.array(target_title_tfidf)))\n",
    "    title_similarity_test.append(cos)\n",
    "    \n",
    "    #group similarity true or false\n",
    "    group_source = source_info[2]\n",
    "    group_target = target_info[2]\n",
    "    \n",
    "    if group_source == group_target:\n",
    "        group_similarity_test.append(1)\n",
    "    else:\n",
    "        group_similarity_test.append(0)\n",
    "        \n",
    "    # number of reviews similarity\n",
    "    review_source = source_info[4]\n",
    "    review_target = target_info[4]\n",
    "    \n",
    "    reviews_num_similarity_test.append(np.absolute(int(review_source)-int(review_target)))\n",
    "    \n",
    "    # same number of words in detailed category\n",
    "    category_source = source_info[6+int(review_source)*4:]\n",
    "    category_target = target_info[6+int(review_target)*4:]\n",
    "    \n",
    "    category_similarity_test.append(len(set(category_source).intersection(set(category_target))))\n",
    "    \n",
    "    # rating similarity\n",
    "    rating_source = source_info[5]\n",
    "    rating_target = target_info[5]\n",
    "    \n",
    "    rating_similarity_test.append(np.absolute(float(rating_source)-float(rating_target)))\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 10000 == True:\n",
    "        print counter, \"testing examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eliminate NaN because of bad tokenizations in titles\n",
    "# some products have trivial title after tokenization\n",
    "for i in range(len(title_similarity_test)):\n",
    "    if math.isnan(title_similarity_test[i]):\n",
    "        title_similarity_test[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum of nodes' degrees \n",
    "node_degree_test = []\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(testing_set)):\n",
    "#for i in range(1):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    \n",
    "    #add node degree\n",
    "    source_degree = G.degree(source)\n",
    "    target_degree = G.degree(target)\n",
    "    if isinstance(source_degree,dict):\n",
    "        source_degree = 0\n",
    "    if isinstance(target_degree,dict):\n",
    "        target_degree = 0\n",
    "    node_degree_test.append(source_degree+target_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distance between two nodes in graph\n",
    "dist_node_test = []\n",
    "\n",
    "counter = 0\n",
    "node_set = G.nodes()\n",
    "for i in xrange(len(testing_set)):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    if (source in node_set) and (target in node_set) and nx.has_path(G,source,target):\n",
    "        dist_node_test.append(-nx.shortest_path_length(G,source,target))\n",
    "    else:\n",
    "        dist_node_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training examples processsed\n",
      "10001 training examples processsed\n",
      "20001 training examples processsed\n",
      "30001 training examples processsed\n",
      "40001 training examples processsed\n",
      "50001 training examples processsed\n",
      "60001 training examples processsed\n",
      "70001 training examples processsed\n",
      "80001 training examples processsed\n",
      "90001 training examples processsed\n",
      "100001 training examples processsed\n",
      "110001 training examples processsed\n",
      "120001 training examples processsed\n",
      "130001 training examples processsed\n",
      "140001 training examples processsed\n",
      "150001 training examples processsed\n",
      "160001 training examples processsed\n",
      "170001 training examples processsed\n",
      "180001 training examples processsed\n",
      "190001 training examples processsed\n",
      "200001 training examples processsed\n",
      "210001 training examples processsed\n",
      "220001 training examples processsed\n",
      "230001 training examples processsed\n",
      "240001 training examples processsed\n",
      "250001 training examples processsed\n",
      "260001 training examples processsed\n",
      "270001 training examples processsed\n",
      "280001 training examples processsed\n",
      "290001 training examples processsed\n",
      "300001 training examples processsed\n",
      "310001 training examples processsed\n",
      "320001 training examples processsed\n",
      "330001 training examples processsed\n",
      "340001 training examples processsed\n",
      "350001 training examples processsed\n",
      "360001 training examples processsed\n",
      "370001 training examples processsed\n",
      "380001 training examples processsed\n",
      "390001 training examples processsed\n",
      "400001 training examples processsed\n",
      "410001 training examples processsed\n",
      "420001 training examples processsed\n",
      "430001 training examples processsed\n",
      "440001 training examples processsed\n",
      "450001 training examples processsed\n",
      "460001 training examples processsed\n",
      "470001 training examples processsed\n",
      "480001 training examples processsed\n",
      "490001 training examples processsed\n",
      "500001 training examples processsed\n",
      "510001 training examples processsed\n",
      "520001 training examples processsed\n"
     ]
    }
   ],
   "source": [
    "# number of common neighbors\n",
    "common_neighbors_test = []\n",
    "\n",
    "counter = 0\n",
    "for i in xrange(len(testing_set)):\n",
    "    source = testing_set[i][0]\n",
    "    target = testing_set[i][1]\n",
    "    \n",
    "    #add node degree\n",
    "    common_neighbors_test.append(len(list(nx.common_neighbors(G,source,target))))\n",
    "    counter += 1\n",
    "    if counter % 10000 == True:\n",
    "        print counter, \"training examples processsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert list of lists into array\n",
    "# documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "testing_features = np.array([title_similarity_test, group_similarity_test, category_similarity_test,reviews_num_similarity_test,rating_similarity_test,node_degree_test,dist_node_test,common_neighbors_test]).T\n",
    "\n",
    "# scale\n",
    "testing_features = preprocessing.scale(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction SVC, Linear SVC\n",
    "predictions = list(classifier.predict(testing_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction Linear regression\n",
    "result = [int(t[2]) for t in testing_set]\n",
    "predictions_linear = []\n",
    "for i in xrange(len(testing_features)):\n",
    "    r = inner(theta,testing_features[i])\n",
    "    if r >= 0.46:\n",
    "        predictions_linear.append(1)\n",
    "    elif r < 0.46 and r >= -0.15:\n",
    "        predictions_linear.append(0)\n",
    "    else:\n",
    "        predictions_linear.append(-1)\n",
    "predictions = predictions_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999176986093\n"
     ]
    }
   ],
   "source": [
    "# Measurement 1, classification accuracy\n",
    "result = [int(t[2]) for t in testing_set]\n",
    "compare = zip(result,predictions)\n",
    "accuracy = 0\n",
    "for c in compare:\n",
    "    if c[0] == c[1]:\n",
    "        accuracy += 1\n",
    "accuracy = accuracy*1.0 / len(compare)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826439578264\n"
     ]
    }
   ],
   "source": [
    "# Measurement 2, label 1 classification accuracy\n",
    "result = [int(t[2]) for t in testing_set]\n",
    "compare = zip(result,predictions)\n",
    "accuracy = 0\n",
    "for c in compare:\n",
    "    if c[0] == c[1] and c[0] == 1:\n",
    "        accuracy += 1\n",
    "print(accuracy*1.0 / (2*len(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# strictly top5 or top10 according to score Measurement 3,4\n",
    "# change values of K for training\n",
    "K = 5\n",
    "all_rank = zip(testing_set,predictions)\n",
    "top5_list = []\n",
    "l = len(G.nodes())\n",
    "for i in range(l):\n",
    "    partial_rank = all_rank[i*(l-1):i*(l-1)+l-2]\n",
    "    partial_rank = sorted(partial_rank,key=lambda x:-x[1])\n",
    "    partial_rank = partial_rank[:K]\n",
    "    tmp = [partial_rank[0][0][0]]\n",
    "    for j in range(K):\n",
    "        tmp.append(partial_rank[j][0][1])\n",
    "    top5_list.append(tmp)\n",
    "top5_list = [t for t in top5_list if len(t) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate recommendation accuracies\n",
    "accuracy = []\n",
    "counter = 0\n",
    "accuracy_sum = 0\n",
    "for i in range(len(top5_list)):\n",
    "    #ground_truth_top5 = testing_list[i]\n",
    "    #ground_truth_set = set(ground_truth_top5[1:])\n",
    "    prediction_top5 = top5_list[i]\n",
    "    prediction_set = set(prediction_top5[1:])\n",
    "    \n",
    "    ground_truth_top5 = [element for element in testing_list if element[0] == prediction_top5[0]][0]\n",
    "    ground_truth_set = set(ground_truth_top5[1:])\n",
    "    if len(ground_truth_set) == 0:\n",
    "        accuracy.append(2.0)\n",
    "    else:\n",
    "        accuracy_t = len(ground_truth_set.intersection(prediction_set))*1.0\\\n",
    "                     / len(ground_truth_set)\n",
    "        accuracy.append([ground_truth_top5[0],accuracy_t])\n",
    "        accuracy_sum += accuracy_t\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5931714719271625"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sum / counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all items satisfied (not used)\n",
    "all_rank = zip(testing_set,predictions)\n",
    "top5_list = []\n",
    "l = len(G.nodes())\n",
    "for i in range(l):\n",
    "    partial_rank = all_rank[i*(l-1):i*(l-1)+l-2]\n",
    "    tmp = [partial_rank[0][0][0]]\n",
    "    partial_rank = [p for p in partial_rank if p[1] == 1.0]\n",
    "    for j in range(len(partial_rank)):\n",
    "        tmp.append(partial_rank[j][0][1])\n",
    "    top5_list.append(tmp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
